# Yolox-tiny-person
tensorflow -> onnx > inference -> onnx runtime gpu



